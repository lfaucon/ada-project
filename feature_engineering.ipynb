{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import json\n",
    "import utils\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"ADA\")\n",
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"session\":\"progfun-002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile('data/spark/preprocessed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161934"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(json.loads).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eventToString(event,verbosity):\n",
    "    if verbosity == 'minimal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\",\n",
    "            \"Video\": lambda x:\"V\",\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    if verbosity == 'normal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\"+str(x['ProblemID']),\n",
    "            \"Video\": lambda x:\"V\"+str(x['VideoID']),\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    if verbosity == 'dates':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\"+str(x['ProblemID'])+\".\"+str(x['Date']),\n",
    "            \"Video\": lambda x:\"V\"+str(x['VideoID'])+\".\"+str(x['Date']),\n",
    "            \"Forum\": lambda x:\"F\"+\".\"+str(x['Date']),\n",
    "        }\n",
    "    return out[event['EventType']](event)\n",
    "\n",
    "def patternToString(pattern,verbosity):\n",
    "    link = \"\" if verbosity == 'minimal' else \"-\" if verbosity == 'normal' else '\\n-> '\n",
    "    return link.join([eventToString(event,verbosity) for event in pattern])\n",
    "\n",
    "def containsProblem(pattern):\n",
    "    return 'P' in patternToString(pattern,'minimal')\n",
    "\n",
    "def getFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[indexOfFirstProblem]\n",
    "\n",
    "def getLastProblem(pattern):\n",
    "    return pattern[-1]\n",
    "\n",
    "def getBeforeLastProblem(pattern):\n",
    "    indexOfLastProblem = patternToString(pattern,'minimal').rfind('P')\n",
    "    return pattern[:(indexOfLastProblem+1)]\n",
    "\n",
    "def getBeforeFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[:indexOfFirstProblem]\n",
    "\n",
    "def getAfterFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[indexOfFirstProblem:]\n",
    "\n",
    "# Uses the method flatMap on the students patterns table to have a table of all the patterns\n",
    "rdd_patterns = (rdd_events_by_students_extract\n",
    "    # x = (studentID,{problemID:pattern,...})\n",
    "    .flatMap(lambda x: [\n",
    "        (pb,x[1][pb]) for pb in x[1].keys() \n",
    "    ])\n",
    "    # x = (problemID,pattern)\n",
    "    .filter(lambda x: containsProblem(x[1]))\n",
    "    # x = (problemID,pattern)\n",
    "    .map(lambda x: (x[0],getBeforeLastProblem(x[1])))\n",
    ")\n",
    "\n",
    "rdd_patterns.persist()\n",
    "for pattern in rdd_patterns.map(lambda x: patternToString(x[1],'minimal')).take(10):\n",
    "    print (pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatures(problem, pattern):\n",
    "    features = {}\n",
    "    \n",
    "    videoBeforeFirstProblem = [video['VideoID'] for video in getBeforeFirstProblem(pattern)]\n",
    "    value = 0. if False in [(videoID in videoBeforeFirstProblem) for videoID in LECTURES_PER_PROBLEM[problem]] else 1. \n",
    "    features['watchedAllVideosBeforeFirstProblem'] = value\n",
    "\n",
    "    value = 1. if len(videoBeforeFirstProblem) != len(set(videoBeforeFirstProblem)) else 0.\n",
    "    features['repeatedVideoBeforeFirstProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Video' for event in pattern])\n",
    "    features['totalNumberOfVideoWatched'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])\n",
    "    features['totalNumberOfProblemSubmissions'] = value \n",
    "            \n",
    "    value = 1. if [v for v in getAfterFirstProblem(pattern) if v['EventType']=='Video'] else 0.\n",
    "    features['watchedSomeVideoAfterFirstProblem'] = value\n",
    "\n",
    "    firstProblem = getFirstProblem(pattern)\n",
    "    value = 1. if pattern[-1]['Grade'] > firstProblem['Grade'] else 0.\n",
    "    features['increaseGradeFromFirstToLastProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])/len(pattern)\n",
    "    features['proportionOfProblemEvents'] = value\n",
    "    \n",
    "    value = firstProblem['TimeStamp'] - pattern[0]['TimeStamp']\n",
    "    features['timeBetweenStartAndFirstProblem'] = value / (3600*24)\n",
    "    \n",
    "    value = pattern[-1]['TimeStamp'] - pattern[0]['TimeStamp']\n",
    "    features['timeBetweenStartAndLastProblem'] = value / (3600*24)\n",
    "    \n",
    "    value = pattern[-1]['TimeStamp'] - firstProblem['TimeStamp']\n",
    "    features['timeBetweenFirstAndLastProblem'] = value / (3600*24)\n",
    "    \n",
    "    value = firstProblem['Grade']\n",
    "    features['firstProblemGrade'] = value\n",
    "    \n",
    "    value = pattern[-1]['Grade']\n",
    "    features['lastProblemGrade'] = value\n",
    "    \n",
    "    value = max(0,(pattern[-1]['Grade']-firstProblem['Grade']))/(10.00001-firstProblem['Grade'])\n",
    "    features['percentageImprovedBetweenFirstAndLastProblem'] = value\n",
    "        \n",
    "    return(features)\n",
    "\n",
    "rdd_pattern_features = (rdd_patterns\n",
    "    # INPUT: (problemID (str), pattern (str))\n",
    "    .map(lambda x: (\n",
    "        x[0],\n",
    "        patternToString(x[1],'dates'),\n",
    "        getFeatures(x[0], x[1])\n",
    "    ))\n",
    ")\n",
    "rdd_pattern_features.persist()\n",
    "\n",
    "FEATURES = list(rdd_pattern_features.first()[2].keys())\n",
    "\n",
    "for featureVector in rdd_pattern_features.take(1):\n",
    "    print('problem', featureVector[0])\n",
    "    print('pattern\\n->', featureVector[1])\n",
    "    pp.pprint(featureVector[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
