{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(\"local[*]\", \"ADA\")\n",
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(100))\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you received 4950 as a result, your spark is working well :) Good job !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"session\":\"progfun-002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PROBLEM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 MaximumSubmissions / 3 AccountUserID / 4 SubmissionNumber / 5 Grade / 6 TimeStamp / 7 DataPackageID / 8 ProblemID / 9 SoftCloseTime / 10 ProblemType / 11 HardCloseTime / 12 Platform / 13 OpenTime / 14 EventType / 15 Title / 16 SessionUserID / 17 UniqueProblemID / 18 UniqueUserID / \n",
      "\n",
      "--- VIDEO_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 OldTime / 3 AccountUserID / 4 CurrentTime / 5 SeekType / 6 TimeStamp / 7 DataPackageID / 8 UniqueRowID / 9 TableName / 10 VideoID / 11 Platform / 12 NewSpeed / 13 EventSource / 14 EventType / 15 SessionUserID / 16 NewTime / 17 OldSpeed / \n",
      "\n",
      "--- FORUM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 PostID / 3 AccountUserID / 4 TimeStamp / 5 DataPackageID / 6 UniqueRowID / 7 TableName / 8 Platform / 9 EventSource / 10 PostType / 11 EventType / 12 JoinID / 13 SessionUserID / "
     ]
    }
   ],
   "source": [
    "# Reading csv files: Create RDD () with one string entry per line in the file\n",
    "rdd_problem_events = sc.textFile(\"data/\"+config['session']+\"_Problem_Events_with_Info.csv\")\n",
    "rdd_video_events = sc.textFile(\"data/\"+config['session']+\"_Video_Events.csv\")\n",
    "rdd_forum_events = sc.textFile(\"data/\"+config['session']+\"_Forum_Events.csv\")\n",
    "\n",
    "# Prints the first line (header) along with indices for each table\n",
    "print(\"--- PROBLEM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_problem_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- VIDEO_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_video_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- FORUM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_forum_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bcd1a54ed6ddb04b4a6fb2906110a01,None,0,None,7,None,1365344171,progfun-002,7,2147483640,Video,2147483640,Coursera,32400,Problem.Check,Lecture 1.2 - Elements of Programming (14:25),c4d4e5fcd2feba9f3234ee8d852dc7b22fbc07e4,f322944718b2ee0e53292118111533c7,21f13b3f6b50a83343b57d2f1d07dbdf \n",
      "\n",
      "db75adce6b87e7ab79242ea0af4b82d4,None,154.696,None,154.697,None,1372391638,progfun-002,00000078c0f0685cc50a25a8d5734a88,Video_Events,33,coursera,1.0,None,Video.Play,ef64fb7b096008f7eaf8441684afdf99af9af54a,None,1.0 \n",
      "\n",
      "f3fdb52859b2511308aee554a573194e,None,17,4108315,1376254235,progfun-002,000006c12322ca29c7013dac42ef1a6a,Forum_Events,coursera,None,Thread,Forum.Thread.View,03b1fa287de5ef57d9c8482195b5167f,None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the filter method to remove the first line\n",
    "rdd_problem_events = rdd_problem_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_video_events = rdd_video_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_forum_events = rdd_forum_events.filter(lambda x: not x.startswith('EventID'))\n",
    "\n",
    "# Prints first record for each table\n",
    "print(rdd_problem_events.first(),\"\\n\") \n",
    "print(rdd_video_events.first(),\"\\n\") \n",
    "print(rdd_forum_events.first(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to parse the string entries from previous dataset\n",
    "def parse_problems(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'Grade':float(data[5]),\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'ProblemID':int(data[8]),\n",
    "        'ProblemType':data[10],\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'Title':data[15],\n",
    "        'SessionUserID':data[16]\n",
    "    }\n",
    "\n",
    "def parse_videos(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'VideoID':int(data[10]),\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'SessionUserID':data[15]\n",
    "    }\n",
    "\n",
    "def parse_forums(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'AccountUserID':data[3],\n",
    "        'TimeStamp':int(data[4]),\n",
    "        'Date':pd.to_datetime(int(data[4]),unit='s'),\n",
    "        'EventType':data[11].split('.')[0],\n",
    "        'EventSubType':data[11].split('.')[1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to filter the string entries from previous dataset\n",
    "def filter_problems(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # Some problem event are quiz inside video, we decide to not consider these\n",
    "        (data[10]=='Assignment')\n",
    "        # We remove IDs of assignments that have been used by the teaching staff for testing the platform\n",
    "        and (not data[8] in ['1','2','3','4','5'])\n",
    "        # Discard assignments with no grade\n",
    "        and (not data[5] in ['None'])\n",
    "    )\n",
    "\n",
    "def filter_videos(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # We remove video that do not belong to the MOOC lectures or ar just Setup videos\n",
    "        (data[10] not in ['9','12','11','10','13','2','29','25','21','27','23'])\n",
    "        # Keeps only \"Play\" EnventSubStype for videos (makes difference between opening the page or starting the video)\n",
    "        and (data[14].split('.')[1] in ['Play','Load'])\n",
    "    )\n",
    "\n",
    "def filter_forums(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90325\n",
      "{'EventSubType': 'Check', 'Grade': 9.32999992371, 'ProblemID': 6, 'EventType': 'Problem', 'TimeStamp': 1366220878, 'Date': Timestamp('2013-04-17 17:47:58'), 'ProblemType': 'Assignment', 'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b', 'Title': 'Functional Sets / Functional Sets'} \n",
      "\n",
      "1168226\n",
      "{'EventType': 'Video', 'VideoID': 33, 'EventSubType': 'Play', 'Date': Timestamp('2013-06-28 03:53:58'), 'TimeStamp': 1372391638, 'SessionUserID': 'ef64fb7b096008f7eaf8441684afdf99af9af54a'} \n",
      "\n",
      "297650\n",
      "{'EventType': 'Forum', 'Date': Timestamp('2013-08-11 20:50:35'), 'AccountUserID': '4108315', 'TimeStamp': 1376254235, 'EventSubType': 'Thread'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the map method to have more workable data\n",
    "rdd_problem_events_parsed = rdd_problem_events.filter(filter_problems).map(parse_problems)\n",
    "rdd_video_events_parsed = rdd_video_events.filter(filter_videos).map(parse_videos)\n",
    "rdd_forum_events_parsed = rdd_forum_events.filter(filter_forums).map(parse_forums)\n",
    "\n",
    "# Prints the count of elements along with the first element of each table\n",
    "print(rdd_problem_events_parsed.count())\n",
    "print(rdd_problem_events_parsed.first(),\"\\n\") \n",
    "print(rdd_video_events_parsed.count()) \n",
    "print(rdd_video_events_parsed.first(),\"\\n\") \n",
    "print(rdd_forum_events_parsed.count()) \n",
    "print(rdd_forum_events_parsed.first(),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForumUserID,AccountUserID,DataPackageID,UniqueRowID,TableName,Platform,SessionUserID \n",
      "\n",
      "297650\n",
      "{'EventType': 'Forum', 'EventSubType': 'Thread', 'Date': Timestamp('2013-05-09 20:22:34'), 'AccountUserID': '2009208', 'TimeStamp': 1368130954, 'SessionUserID': '16e564ed1e9b7104acde8f075c26a1872695fb5e'}\n"
     ]
    }
   ],
   "source": [
    "# Handles issue with the forum events table having 'AccountUserID' instead of 'SessionUserID'\n",
    "# Using the table progfun-002_User_Hash_Mapping\n",
    "rdd_user_mapping = sc.textFile(\"data/\"+config['session']+\"_User_Hash_Mapping.csv\")\n",
    "print(rdd_user_mapping.take(1)[0],\"\\n\")\n",
    "\n",
    "def f(x):\n",
    "    x[1][1]['SessionUserID']=x[1][0] \n",
    "    return x[1][1]\n",
    "\n",
    "rdd_forum_events_parsed = (rdd_user_mapping\n",
    "    # removes header\n",
    "    .filter(lambda x: not x.startswith(\"ForumUserID\"))\n",
    "    # maps to have the format (Key=AccountUserID,Value=SessionUserID)\n",
    "    .map(lambda x:(x.split(\",\")[1],x.split(\",\")[6]))\n",
    "    # join with rdd_forum_event to get format (map to have the (Key=AccountUserID,Value=(SessionUserID,EventObject)) format)\n",
    "    .join(rdd_forum_events_parsed\n",
    "        # map to have the (Key=AccountUserID,Value=EventObject) format\n",
    "        .map(lambda x: (x['AccountUserID'],x))\n",
    "    )\n",
    "    # Use the function f to update EventObject with the joined SessionUserID\n",
    "    .map(f)\n",
    ")\n",
    "\n",
    "print(rdd_forum_events_parsed.count())\n",
    "print(rdd_forum_events_parsed.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556201\n",
      "{'EventType': 'Problem', 'EventSubType': 'Check', 'Grade': 9.32999992371, 'ProblemID': 6, 'Title': 'Functional Sets / Functional Sets', 'TimeStamp': 1366220878, 'Date': Timestamp('2013-04-17 17:47:58'), 'ProblemType': 'Assignment', 'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b'}\n"
     ]
    }
   ],
   "source": [
    "# Concatenantes all three table into one big table\n",
    "rdd_events = (rdd_problem_events_parsed\n",
    "    .union(rdd_video_events_parsed)\n",
    "    .union(rdd_forum_events_parsed)\n",
    ")\n",
    "rdd_events.persist()\n",
    "print(rdd_events.count())\n",
    "print(rdd_events.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing meta data\n",
    "The goal is to have the table linking VideoIDs to corresponding ProblemIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments = sorted((rdd_problem_events_parsed\n",
    "    .map(lambda x: (x['ProblemID'],x['Title']))\n",
    "    .distinct()\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd_video_info = sc.textFile(\"data/\"+config['session']+\"_Video_Info.csv\")\n",
    "videos = sorted((rdd_video_info\n",
    "    .map(lambda x: x.split(','))\n",
    "    .filter(lambda x: not x[1] in ['None', 'OpenTime'] )\n",
    "    .map(lambda x: (int(x[7]),x[2]))\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: [35, 37, 39, 41, 43, 47, 49],\n",
       " 7: [3, 4, 5, 6, 7, 8, 33],\n",
       " 12: [51, 53, 75],\n",
       " 14: [71, 81, 85, 79, 87, 77],\n",
       " 17: [109, 105, 115, 107, 103, 113, 111],\n",
       " 20: [123, 117, 125, 121, 127, 119]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Made by hand... so painful\n",
    "LECTURES_PER_PROBLEM = {\n",
    "    7: [3,4,5,6,7,8,33], # Lecture 1\n",
    "    6: [35,37,39,41,43,47,49], # Lecture 2\n",
    "    12: [51,53,75], # Lecture 3\n",
    "    14: [71,81,85,79,87,77], # Lecture 4\n",
    "    17: [109,105,115,107,103,113,111], # Lecture 6\n",
    "    20: [123,117,125,121,127,119] # Lecture 7\n",
    "}\n",
    "LECTURES_PER_PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{51: 12, 3: 7, 4: 7, 49: 6, 6: 7, 7: 7, 8: 7, 119: 20, 77: 14, 79: 14, 43: 6, 75: 12, 85: 14, 87: 14, 39: 6, 71: 14, 111: 17, 81: 14, 5: 7, 33: 7, 35: 6, 37: 6, 103: 17, 105: 17, 107: 17, 109: 17, 47: 6, 113: 17, 53: 12, 115: 17, 117: 20, 41: 6, 121: 20, 123: 20, 125: 20, 127: 20}\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_PER_LECTURE = {}\n",
    "for pb in LECTURES_PER_PROBLEM.keys():\n",
    "    for lc in LECTURES_PER_PROBLEM[pb]:\n",
    "        PROBLEM_PER_LECTURE[lc]=pb\n",
    "print(PROBLEM_PER_LECTURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping & Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 24626\n"
     ]
    }
   ],
   "source": [
    "# uses the function groupByKey on our events with the key 'SessionStudentID'\n",
    "rdd_events_by_students = (rdd_events\n",
    "    .map(lambda x: (x['SessionUserID'],x))\n",
    "    # Groups the list of event by student\n",
    "    .groupByKey()\n",
    "    # Sorts each student sequence by the timestamp\n",
    "    .map(lambda x: (x[0],sorted(x[1], key=(lambda event: event['TimeStamp']))))\n",
    ")\n",
    "rdd_events_by_students.persist()\n",
    "print(\"Number of students: %d\" % rdd_events_by_students.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to have a friendly way to print the events\n",
    "def eventToString(event):\n",
    "    return {\n",
    "        \"Problem\": lambda x: \"(P \"+str(event['ProblemID'])+\")\",\n",
    "        \"Video\": lambda x: \"(V \"+str(event['VideoID'])+\")\",\n",
    "        \"Forum\": lambda x: \"(F)\"\n",
    "    }[event['EventType']](event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_STUDENTS={\n",
    "    '6ea6949ca133acede360d3573f9d1168b3d70b51':'very good student',\n",
    "    '3b305429f93de02637949578a5f9e23f13eb0726':'did two problems',\n",
    "    '865981d5b40a693bafbadae4b1df769be03a25c3':'watched 8 videos',\n",
    "    '67cdae6073d1089b695e2a615a01187586ad7ba6':'normal student',\n",
    "    'fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f':'the very best student',\n",
    "    '295b3496278626b6d337812b1882b756336fd633':'whatdup with this guy?'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6ea6949ca133acede360d3573f9d1168b3d70b51 : very good student\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 6) (V 6) (V 6) (V 6) (V 6) (V 7) (V 7) (V 7) (V 33) (V 33) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) (V 51) (V 51) (V 51) (V 53) (V 53) (V 53) (V 75) (V 75) (V 75) (V 75) (P 12) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (V 73) (V 89) (V 91) (V 93) (V 95) (V 95) (V 97) (V 101) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (V 109) (V 111) (V 113) (V 107) (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (F) (F) (P 20) (F) (F) (V 125) (V 125) (P 20) (F) \n",
      "\n",
      " 865981d5b40a693bafbadae4b1df769be03a25c3 : watched 8 videos\n",
      "(V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 7) (V 33) (V 35) (V 35) (V 35) (V 35) \n",
      "\n",
      " 3b305429f93de02637949578a5f9e23f13eb0726 : did two problems\n",
      "(P 7) (P 6) \n",
      "\n",
      " fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f : the very best student\n",
      "(V 8) (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 7) (V 7) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 43) (V 47) (V 47) (V 47) (V 47) (V 47) (V 47) (V 49) (V 49) (F) (F) (F) (F) (F) (P 7) (P 7) (P 7) (F) (P 7) (P 7) (P 6) (P 6) (V 51) (V 51) (V 53) (V 53) (V 53) (V 53) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 53) (V 75) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (F) (F) (F) (F) (V 79) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (V 71) (P 12) (P 12) (P 12) (P 12) (V 73) (V 73) (V 73) (P 14) (P 14) (P 14) (P 14) (V 73) (V 89) (V 91) (V 91) (V 93) (V 95) (V 97) (V 101) (P 14) (V 103) (V 103) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 111) (V 111) (V 111) (V 111) (V 113) (V 113) (V 115) (V 115) (V 117) (V 119) (V 121) (V 121) (V 123) (P 17) (P 17) (V 125) (V 127) (P 17) (P 20) (P 20) (P 20) (P 17) (P 17) (P 17) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (P 17) \n",
      "\n",
      " 295b3496278626b6d337812b1882b756336fd633 : whatdup with this guy?\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 7) (V 33) (P 7) (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 47) (V 49) (P 6) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 89) (V 89) (V 89) (V 91) (V 91) (V 91) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 95) (V 95) (V 95) (V 95) (V 97) (V 97) (V 97) (V 101) (V 101) (V 101) (V 103) (V 103) (V 103) (V 105) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 109) (V 109) (V 111) (V 111) (V 111) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 115) (V 115) (V 121) (P 17) (P 17) (V 117) (V 117) (V 117) (V 117) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 121) (V 121) (V 121) (V 121) (V 121) (V 121) (V 123) (V 123) (V 123) (V 125) (V 125) (V 125) (V 125) (P 20) (V 127) \n",
      "\n",
      " 67cdae6073d1089b695e2a615a01187586ad7ba6 : normal student\n",
      "(V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) (F) (F) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 87) (V 71) (P 14) (P 12) (P 12) (P 17) (P 20) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) \n"
     ]
    }
   ],
   "source": [
    "# Looks at the data for a few students\n",
    "for studentID,events in rdd_events_by_students.filter(lambda x: x[0] in TEST_STUDENTS.keys()).collect():\n",
    "    print('\\n',studentID,':',TEST_STUDENTS[studentID])\n",
    "    for event in events:\n",
    "        print(eventToString(event), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting learning patterns\n",
    "The goal is to extract what a students does between a failed attempt at an assignment and a successful attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The goal is to extract the list corresponding to each Problem\n",
    "def extractPatterns(events):\n",
    "    patterns = {}\n",
    "    for problemID in LECTURES_PER_PROBLEM.keys():\n",
    "        patterns[problemID]=[]\n",
    "    # for each problem measure first and last entry\n",
    "    for event in events:\n",
    "        if event['EventType']=='Problem':\n",
    "            patterns[event['ProblemID']].append(event)\n",
    "        if event['EventType']=='Video':\n",
    "            if event['VideoID'] in PROBLEM_PER_LECTURE.keys():\n",
    "                patterns[PROBLEM_PER_LECTURE[event['VideoID']]].append(event)\n",
    "    return patterns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal is to concatenate small sub events into one big event\n",
    "# For example Play/Pause/Play/Pause/Play/Pause on a video counts as only a Video event\n",
    "def eventConcat(events):\n",
    "    if len(events)<2:\n",
    "        return events\n",
    "    res=[events[0]]\n",
    "    for event in events[1:]:\n",
    "        if (\n",
    "            event['EventType']!=res[-1]['EventType'] \n",
    "            or event.get('VideoID',None)!=res[-1].get('VideoID',None)\n",
    "            or event['EventType']=='Problem'\n",
    "        ):\n",
    "            res.append(event)\n",
    "    return res\n",
    "\n",
    "def patternsConcat(patterns):\n",
    "    res = {}\n",
    "    for pattern in patterns.keys():\n",
    "        res[pattern]=eventConcat(patterns[pattern])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ea6949ca133acede360d3573f9d1168b3d70b51 very good student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (V 109) (V 111) (V 113) (V 107) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (P 20) (V 125) (P 20) \n",
      "\n",
      "865981d5b40a693bafbadae4b1df769be03a25c3 watched 8 videos\n",
      "6\t>>>  (V 35) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "3b305429f93de02637949578a5f9e23f13eb0726 did two problems\n",
      "6\t>>>  (P 6) \n",
      "7\t>>>  (P 7) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f the very best student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 33) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (P 20) (P 20) (P 20) \n",
      "\n",
      "295b3496278626b6d337812b1882b756336fd633 whatdup with this guy?\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) \n",
      "20\t>>>  (V 121) (V 117) (V 119) (V 121) (V 123) (V 125) (P 20) (V 127) \n",
      "\n",
      "67cdae6073d1089b695e2a615a01187586ad7ba6 normal student\n",
      "6\t>>>  (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) \n",
      "7\t>>>  (V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) \n",
      "17\t>>>  (P 17) \n",
      "20\t>>>  (P 20) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd_events_by_students_extract = (rdd_events_by_students\n",
    "    # x = (studentID,eventList)\n",
    "    .map(lambda x: (x[0],extractPatterns(x[1])))\n",
    "    # x = (studentID,{problemID:pattern,...})\n",
    "    .map(lambda x: (x[0],patternsConcat(x[1])))\n",
    ")\n",
    "\n",
    "rdd_events_by_students_extract.persist()\n",
    "\n",
    "# Looks at the data for a student, now that it's sorted by TimeStamps\n",
    "def displayStudentsPatterns(rdd,students):\n",
    "    for studentID,patterns in rdd.filter(lambda x:x[0] in students.keys()).collect():\n",
    "        print(studentID, students[studentID])\n",
    "        for pb in sorted(patterns.keys()):\n",
    "            print(pb,end='\\t>>>  ')\n",
    "            for event in patterns[pb]:\n",
    "                print(eventToString(event), end=\" \")\n",
    "            print()\n",
    "        print()\n",
    "\n",
    "displayStudentsPatterns(rdd_events_by_students_extract,TEST_STUDENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VVVVVVVVVVVP\n",
      "VVVVVVVP\n",
      "VVVP\n",
      "VVVVP\n",
      "VVVVPP\n",
      "PP\n",
      "P\n",
      "VVVVP\n",
      "VVVVVVVP\n",
      "VVVVVVVP\n"
     ]
    }
   ],
   "source": [
    "def eventToString(event,verbosity):\n",
    "    if verbosity == 'minimal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\",\n",
    "            \"Video\": lambda x:\"V\",\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    if verbosity == 'normal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\"+str(x['ProblemID']),\n",
    "            \"Video\": lambda x:\"V\"+str(x['VideoID']),\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    if verbosity == 'dates':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\"+str(x['ProblemID'])+\".\"+str(x['Date']),\n",
    "            \"Video\": lambda x:\"V\"+str(x['VideoID'])+\".\"+str(x['Date']),\n",
    "            \"Forum\": lambda x:\"F\"+\".\"+str(x['Date']),\n",
    "        }\n",
    "    return out[event['EventType']](event)\n",
    "\n",
    "def patternToString(pattern,verbosity):\n",
    "    link = \"\" if verbosity == 'minimal' else \"-\" if verbosity == 'normal' else '\\n-> '\n",
    "    return link.join([eventToString(event,verbosity) for event in pattern])\n",
    "\n",
    "def containsProblem(pattern):\n",
    "    return 'P' in patternToString(pattern,'minimal')\n",
    "\n",
    "def getFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[indexOfFirstProblem]\n",
    "\n",
    "def getLastProblem(pattern):\n",
    "    return pattern[-1]\n",
    "\n",
    "def getBeforeLastProblem(pattern):\n",
    "    indexOfLastProblem = patternToString(pattern,'minimal').rfind('P')\n",
    "    return pattern[:(indexOfLastProblem+1)]\n",
    "\n",
    "def getBeforeFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[:indexOfFirstProblem]\n",
    "\n",
    "def getAfterFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[indexOfFirstProblem:]\n",
    "\n",
    "# Uses the method flatMap on the students patterns table to have a table of all the patterns\n",
    "rdd_patterns = (rdd_events_by_students_extract\n",
    "    # x = (studentID,{problemID:pattern,...})\n",
    "    .flatMap(lambda x: [\n",
    "        (pb,x[1][pb]) for pb in x[1].keys() \n",
    "    ])\n",
    "    # x = (problemID,pattern)\n",
    "    .filter(lambda x: containsProblem(x[1]))\n",
    "    # x = (problemID,pattern)\n",
    "    .map(lambda x: (x[0],getBeforeLastProblem(x[1])))\n",
    ")\n",
    "\n",
    "rdd_patterns.persist()\n",
    "for pattern in rdd_patterns.map(lambda x: patternToString(x[1],'minimal')).take(10):\n",
    "    print (pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'lastProblemGrade',\n",
      "    'watchedSomeVideoAfterFirstProblem',\n",
      "    'totalNumberOfVideoWatched',\n",
      "    'timeBetweenFirstAndLastProblem',\n",
      "    'increaseGradeFromFirstToLastProblem',\n",
      "    'percentageImprovedBetweenFirstAndLastProblem',\n",
      "    'watchedAllVideosBeforeFirstProblem',\n",
      "    'proportionOfProblemEvents',\n",
      "    'timeBetweenStartAndFirstProblem',\n",
      "    'firstProblemGrade',\n",
      "    'totalNumberOfProblemSubmissions',\n",
      "    'timeBetweenStartAndLastProblem',\n",
      "    'repeatedVideoBeforeFirstProblem']\n",
      "problem 6\n",
      "pattern\n",
      "-> V35.2013-04-04 11:47:32\n",
      "-> V37.2013-04-04 12:42:22\n",
      "-> V39.2013-04-04 14:09:38\n",
      "-> V41.2013-04-04 14:21:10\n",
      "-> V43.2013-04-04 14:22:07\n",
      "-> V35.2013-04-14 12:20:06\n",
      "-> V41.2013-04-14 12:22:23\n",
      "-> V43.2013-04-14 12:22:59\n",
      "-> V47.2013-04-14 13:01:38\n",
      "-> V49.2013-04-14 13:20:42\n",
      "-> V37.2013-04-14 13:23:53\n",
      "-> P6.2013-04-14 14:07:01\n",
      "{   'firstProblemGrade': 10.0,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 10.0,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.08333333333333333,\n",
      "    'repeatedVideoBeforeFirstProblem': 1.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0,\n",
      "    'timeBetweenStartAndFirstProblem': 872369,\n",
      "    'timeBetweenStartAndLastProblem': 872369,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 11,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 7\n",
      "pattern\n",
      "-> V8.2013-03-27 09:31:54\n",
      "-> V3.2013-03-27 10:26:43\n",
      "-> V4.2013-03-27 10:43:06\n",
      "-> V5.2013-03-27 10:48:07\n",
      "-> V6.2013-03-27 11:00:08\n",
      "-> V7.2013-03-27 11:11:57\n",
      "-> V33.2013-03-27 11:23:02\n",
      "-> P7.2013-04-04 12:49:08\n",
      "{   'firstProblemGrade': 10.0,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 10.0,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.125,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0,\n",
      "    'timeBetweenStartAndFirstProblem': 703034,\n",
      "    'timeBetweenStartAndLastProblem': 703034,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 7,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 12\n",
      "pattern\n",
      "-> V51.2013-04-16 08:53:40\n",
      "-> V53.2013-04-22 11:42:43\n",
      "-> V75.2013-04-22 12:03:14\n",
      "-> P12.2013-04-28 11:55:25\n",
      "{   'firstProblemGrade': 7.82000017166,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 7.82000017166,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.25,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0,\n",
      "    'timeBetweenStartAndFirstProblem': 1047705,\n",
      "    'timeBetweenStartAndLastProblem': 1047705,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 3,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 14\n",
      "pattern\n",
      "-> V79.2013-04-28 11:56:18\n",
      "-> V77.2013-04-28 12:10:20\n",
      "-> V81.2013-04-28 12:46:33\n",
      "-> V85.2013-04-28 12:58:28\n",
      "-> P14.2013-04-28 13:45:29\n",
      "{   'firstProblemGrade': 9.05000019073,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 9.05000019073,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.2,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0,\n",
      "    'timeBetweenStartAndFirstProblem': 6551,\n",
      "    'timeBetweenStartAndLastProblem': 6551,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 4,\n",
      "    'watchedAllVideosBeforeFirstProblem': 0.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 6\n",
      "pattern\n",
      "-> V47.2013-04-12 17:07:50\n",
      "-> V39.2013-04-12 17:08:28\n",
      "-> V37.2013-04-12 17:08:58\n",
      "-> V39.2013-04-12 19:58:54\n",
      "-> P6.2013-04-12 20:53:45\n",
      "-> P6.2013-04-12 21:44:34\n",
      "{   'firstProblemGrade': 8.67000007629,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 8.67000007629,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.3333333333333333,\n",
      "    'repeatedVideoBeforeFirstProblem': 1.0,\n",
      "    'timeBetweenFirstAndLastProblem': 3049,\n",
      "    'timeBetweenStartAndFirstProblem': 13555,\n",
      "    'timeBetweenStartAndLastProblem': 16604,\n",
      "    'totalNumberOfProblemSubmissions': 2,\n",
      "    'totalNumberOfVideoWatched': 4,\n",
      "    'watchedAllVideosBeforeFirstProblem': 0.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getFeatures(problem, pattern):\n",
    "    features = {}\n",
    "    \n",
    "    videoBeforeFirstProblem = [video['VideoID'] for video in getBeforeFirstProblem(pattern)]\n",
    "    value = 0. if False in [(videoID in videoBeforeFirstProblem) for videoID in LECTURES_PER_PROBLEM[problem]] else 1. \n",
    "    features['watchedAllVideosBeforeFirstProblem'] = value\n",
    "\n",
    "    value = 1. if len(videoBeforeFirstProblem) != len(set(videoBeforeFirstProblem)) else 0.\n",
    "    features['repeatedVideoBeforeFirstProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Video' for event in pattern])\n",
    "    features['totalNumberOfVideoWatched'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])\n",
    "    features['totalNumberOfProblemSubmissions'] = value \n",
    "            \n",
    "    value = 1. if [v for v in getAfterFirstProblem(pattern) if v['EventType']=='Video'] else 0.\n",
    "    features['watchedSomeVideoAfterFirstProblem'] = value\n",
    "\n",
    "    firstProblem = getFirstProblem(pattern)\n",
    "    value = 1. if pattern[-1]['Grade'] > firstProblem['Grade'] else 0.\n",
    "    features['increaseGradeFromFirstToLastProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])/len(pattern)\n",
    "    features['proportionOfProblemEvents'] = value\n",
    "    \n",
    "    value = firstProblem['TimeStamp'] - pattern[0]['TimeStamp']\n",
    "    features['timeBetweenStartAndFirstProblem'] = value\n",
    "    \n",
    "    value = pattern[-1]['TimeStamp'] - pattern[0]['TimeStamp']\n",
    "    features['timeBetweenStartAndLastProblem'] = value\n",
    "    \n",
    "    value = pattern[-1]['TimeStamp'] - firstProblem['TimeStamp']\n",
    "    features['timeBetweenFirstAndLastProblem'] = value\n",
    "    \n",
    "    value = firstProblem['Grade']\n",
    "    features['firstProblemGrade'] = value\n",
    "    \n",
    "    value = pattern[-1]['Grade']\n",
    "    features['lastProblemGrade'] = value\n",
    "    \n",
    "    value = max(0,(pattern[-1]['Grade']-firstProblem['Grade']))/(10.001-firstProblem['Grade'])\n",
    "    features['percentageImprovedBetweenFirstAndLastProblem'] = value\n",
    "        \n",
    "    return(features)\n",
    "\n",
    "rdd_pattern_features = (rdd_patterns\n",
    "    # x = (problemID, pattern)\n",
    "    .map(lambda x: (\n",
    "        x[0],\n",
    "        patternToString(x[1],'dates'),\n",
    "        getFeatures(x[0], x[1])\n",
    "    ))\n",
    ")\n",
    "rdd_pattern_features.persist()\n",
    "\n",
    "FEATURES = list(rdd_pattern_features.first()[2].keys())\n",
    "pp.pprint(FEATURES)\n",
    "\n",
    "for featureVector in rdd_pattern_features.take(5):\n",
    "    print('problem', featureVector[0])\n",
    "    print('pattern\\n->', featureVector[1])\n",
    "    pp.pprint(featureVector[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(features=DenseVector([0.3466, -0.1934, 1.5899, -0.1574, -0.8569, -0.8183, 0.9361, -1.0298, 1.2526, 0.5734, -0.6153, 1.0474, 1.6754]))\n"
     ]
    }
   ],
   "source": [
    "rdd_kmeans = (rdd_pattern_features\n",
    "    # x = (_,_,feature_dict)\n",
    "    .map(lambda x: x[2])        \n",
    ")\n",
    "\n",
    "FEATURE_AVG = {}\n",
    "FEATURE_STD = {} \n",
    "for feature in FEATURES:\n",
    "    stats = rdd_kmeans.map(lambda x:x[feature]).stats()\n",
    "    FEATURE_AVG[feature] = stats.mean()\n",
    "    FEATURE_STD[feature] = stats.stdev()\n",
    "\n",
    "rdd_kmeans = (rdd_kmeans\n",
    "    .map(lambda x: [(x[feature]-FEATURE_AVG[feature])/FEATURE_STD[feature] for feature in FEATURES])\n",
    "    .map(lambda x : Row(features=(Vectors.dense(x))))\n",
    ")\n",
    "\n",
    "print(rdd_kmeans.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 515279.6222533948\n",
      "Cluster Centers: \n",
      "[ 0.09314352  0.23726606  0.03553959  0.18295425  1.15882018  1.10995259\n",
      "  0.01187451  0.15216173 -0.02365987 -0.44525713  0.75304642  0.06191297\n",
      "  0.04437173]\n",
      "[-0.06865588 -0.17488829 -0.02619615 -0.13485517 -0.8541638  -0.81814361\n",
      " -0.00875268 -0.11215808  0.01743964  0.32819805 -0.55506886 -0.04563592\n",
      " -0.03270631]\n"
     ]
    }
   ],
   "source": [
    "# Infer the schema, and register the DataFrame as a table.\n",
    "dataset_kmeans = sqlContext.createDataFrame(rdd_kmeans)\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset_kmeans)\n",
    "\n",
    "# Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "wssse = model.computeCost(dataset_kmeans)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " 'V35.2013-04-04 11:47:32\\n-> V37.2013-04-04 12:42:22\\n-> V39.2013-04-04 14:09:38\\n-> V41.2013-04-04 14:21:10\\n-> V43.2013-04-04 14:22:07\\n-> V35.2013-04-14 12:20:06\\n-> V41.2013-04-14 12:22:23\\n-> V43.2013-04-14 12:22:59\\n-> V47.2013-04-14 13:01:38\\n-> V49.2013-04-14 13:20:42\\n-> V37.2013-04-14 13:23:53\\n-> P6.2013-04-14 14:07:01',\n",
       " {'firstProblemGrade': 10.0,\n",
       "  'increaseGradeFromFirstToLastProblem': 0.0,\n",
       "  'lastProblemGrade': 10.0,\n",
       "  'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
       "  'proportionOfProblemEvents': 0.08333333333333333,\n",
       "  'repeatedVideoBeforeFirstProblem': 1.0,\n",
       "  'timeBetweenFirstAndLastProblem': 0,\n",
       "  'timeBetweenStartAndFirstProblem': 872369,\n",
       "  'timeBetweenStartAndLastProblem': 872369,\n",
       "  'totalNumberOfProblemSubmissions': 1,\n",
       "  'totalNumberOfVideoWatched': 11,\n",
       "  'watchedAllVideosBeforeFirstProblem': 1.0,\n",
       "  'watchedSomeVideoAfterFirstProblem': 0.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_pattern_features.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22676\n",
      "5453\n"
     ]
    }
   ],
   "source": [
    "rdd = (rdd_pattern_features\n",
    "       .map(lambda x: x[2])\n",
    "       .filter(lambda x: x['totalNumberOfProblemSubmissions']>1)\n",
    ")\n",
    "print(rdd.count())\n",
    "print(rdd.filter(lambda x: x['lastProblemGrade']<10).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
