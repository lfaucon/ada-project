{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA - Project\n",
    "## With Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(\"local[*]\", \"ADA\")\n",
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(100))\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you received 4950 as a result, your spark is working well :) Good job !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"session\":\"progfun-002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PROBLEM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 MaximumSubmissions / 3 AccountUserID / 4 SubmissionNumber / 5 Grade / 6 TimeStamp / 7 DataPackageID / 8 ProblemID / 9 SoftCloseTime / 10 ProblemType / 11 HardCloseTime / 12 Platform / 13 OpenTime / 14 EventType / 15 Title / 16 SessionUserID / 17 UniqueProblemID / 18 UniqueUserID / \n",
      "\n",
      "--- VIDEO_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 OldTime / 3 AccountUserID / 4 CurrentTime / 5 SeekType / 6 TimeStamp / 7 DataPackageID / 8 UniqueRowID / 9 TableName / 10 VideoID / 11 Platform / 12 NewSpeed / 13 EventSource / 14 EventType / 15 SessionUserID / 16 NewTime / 17 OldSpeed / \n",
      "\n",
      "--- FORUM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 PostID / 3 AccountUserID / 4 TimeStamp / 5 DataPackageID / 6 UniqueRowID / 7 TableName / 8 Platform / 9 EventSource / 10 PostType / 11 EventType / 12 JoinID / 13 SessionUserID / "
     ]
    }
   ],
   "source": [
    "# Reading csv files: Create RDD () with one string entry per line in the file\n",
    "rdd_problem_events = sc.textFile(\"data/\"+config['session']+\"_Problem_Events_with_Info.csv\")\n",
    "rdd_video_events = sc.textFile(\"data/\"+config['session']+\"_Video_Events.csv\")\n",
    "rdd_forum_events = sc.textFile(\"data/\"+config['session']+\"_Forum_Events.csv\")\n",
    "\n",
    "# Prints the first line (header) along with indices for each table\n",
    "print(\"--- PROBLEM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_problem_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- VIDEO_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_video_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- FORUM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_forum_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bcd1a54ed6ddb04b4a6fb2906110a01,None,0,None,7,None,1365344171,progfun-002,7,2147483640,Video,2147483640,Coursera,32400,Problem.Check,Lecture 1.2 - Elements of Programming (14:25),c4d4e5fcd2feba9f3234ee8d852dc7b22fbc07e4,f322944718b2ee0e53292118111533c7,21f13b3f6b50a83343b57d2f1d07dbdf \n",
      "\n",
      "db75adce6b87e7ab79242ea0af4b82d4,None,154.696,None,154.697,None,1372391638,progfun-002,00000078c0f0685cc50a25a8d5734a88,Video_Events,33,coursera,1.0,None,Video.Play,ef64fb7b096008f7eaf8441684afdf99af9af54a,None,1.0 \n",
      "\n",
      "f3fdb52859b2511308aee554a573194e,None,17,4108315,1376254235,progfun-002,000006c12322ca29c7013dac42ef1a6a,Forum_Events,coursera,None,Thread,Forum.Thread.View,03b1fa287de5ef57d9c8482195b5167f,None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the filter method to remove the first line\n",
    "rdd_problem_events = rdd_problem_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_video_events = rdd_video_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_forum_events = rdd_forum_events.filter(lambda x: not x.startswith('EventID'))\n",
    "\n",
    "# Prints first record for each table\n",
    "print(rdd_problem_events.first(),\"\\n\") \n",
    "print(rdd_video_events.first(),\"\\n\") \n",
    "print(rdd_forum_events.first(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to parse the string entries from previous dataset\n",
    "def parse_problems(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'Grade':float(data[5]),\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'ProblemID':int(data[8]),\n",
    "        'ProblemType':data[10],\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'Title':data[15],\n",
    "        'SessionUserID':data[16]\n",
    "    }\n",
    "\n",
    "def parse_videos(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'VideoID':int(data[10]),\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'SessionUserID':data[15]\n",
    "    }\n",
    "\n",
    "def parse_forums(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'AccountUserID':data[3],\n",
    "        'TimeStamp':int(data[4]),\n",
    "        'Date':pd.to_datetime(int(data[4]),unit='s'),\n",
    "        'EventType':data[11].split('.')[0],\n",
    "        'EventSubType':data[11].split('.')[1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to filter the string entries from previous dataset\n",
    "def filter_problems(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # Some problem event are quiz inside video, we decide to not consider these\n",
    "        (data[10]=='Assignment')\n",
    "        # We remove IDs of assignments that have been used by the teaching staff for testing the platform\n",
    "        and (not data[8] in ['1','2','3','4','5'])\n",
    "        # Discard assignments with no grade\n",
    "        and (not data[5] in ['None'])\n",
    "    )\n",
    "\n",
    "def filter_videos(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # We remove video that do not belong to the MOOC lectures or ar just Setup videos\n",
    "        (data[10] not in ['9','12','11','10','13','2','29','25','21','27','23'])\n",
    "        # Keeps only \"Play\" EnventSubStype for videos (makes difference between opening the page or starting the video)\n",
    "        and (data[14].split('.')[1] in ['Play','Load'])\n",
    "    )\n",
    "\n",
    "def filter_forums(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90325\n",
      "{'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b', 'ProblemID': 6, 'TimeStamp': 1366220878, 'ProblemType': 'Assignment', 'EventSubType': 'Check', 'Date': Timestamp('2013-04-17 17:47:58'), 'Grade': 9.32999992371, 'Title': 'Functional Sets / Functional Sets', 'EventType': 'Problem'} \n",
      "\n",
      "1168226\n",
      "{'SessionUserID': 'ef64fb7b096008f7eaf8441684afdf99af9af54a', 'VideoID': 33, 'EventSubType': 'Play', 'Date': Timestamp('2013-06-28 03:53:58'), 'TimeStamp': 1372391638, 'EventType': 'Video'} \n",
      "\n",
      "297650\n",
      "{'EventSubType': 'Thread', 'Date': Timestamp('2013-08-11 20:50:35'), 'TimeStamp': 1376254235, 'AccountUserID': '4108315', 'EventType': 'Forum'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the map method to have more workable data\n",
    "rdd_problem_events_parsed = rdd_problem_events.filter(filter_problems).map(parse_problems)\n",
    "rdd_video_events_parsed = rdd_video_events.filter(filter_videos).map(parse_videos)\n",
    "rdd_forum_events_parsed = rdd_forum_events.filter(filter_forums).map(parse_forums)\n",
    "\n",
    "# Prints the count of elements along with the first element of each table\n",
    "print(rdd_problem_events_parsed.count())\n",
    "print(rdd_problem_events_parsed.first(),\"\\n\") \n",
    "print(rdd_video_events_parsed.count()) \n",
    "print(rdd_video_events_parsed.first(),\"\\n\") \n",
    "print(rdd_forum_events_parsed.count()) \n",
    "print(rdd_forum_events_parsed.first(),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForumUserID,AccountUserID,DataPackageID,UniqueRowID,TableName,Platform,SessionUserID \n",
      "\n",
      "297650\n",
      "{'SessionUserID': '16e564ed1e9b7104acde8f075c26a1872695fb5e', 'EventSubType': 'Thread', 'Date': Timestamp('2013-05-09 20:22:34'), 'TimeStamp': 1368130954, 'AccountUserID': '2009208', 'EventType': 'Forum'}\n"
     ]
    }
   ],
   "source": [
    "# Handles issue with the forum events table having 'AccountUserID' instead of 'SessionUserID'\n",
    "# Using the table progfun-002_User_Hash_Mapping\n",
    "rdd_user_mapping = sc.textFile(\"data/\"+config['session']+\"_User_Hash_Mapping.csv\")\n",
    "print(rdd_user_mapping.take(1)[0],\"\\n\")\n",
    "\n",
    "def f(x):\n",
    "    x[1][1]['SessionUserID']=x[1][0] \n",
    "    return x[1][1]\n",
    "\n",
    "rdd_forum_events_parsed = (rdd_user_mapping\n",
    "    # removes header\n",
    "    .filter(lambda x: not x.startswith(\"ForumUserID\"))\n",
    "    # maps to have the format (Key=AccountUserID,Value=SessionUserID)\n",
    "    .map(lambda x:(x.split(\",\")[1],x.split(\",\")[6]))\n",
    "    # join with rdd_forum_event to get format (map to have the (Key=AccountUserID,Value=(SessionUserID,EventObject)) format)\n",
    "    .join(rdd_forum_events_parsed\n",
    "        # map to have the (Key=AccountUserID,Value=EventObject) format\n",
    "        .map(lambda x: (x['AccountUserID'],x))\n",
    "    )\n",
    "    # Use the function f to update EventObject with the joined SessionUserID\n",
    "    .map(f)\n",
    ")\n",
    "\n",
    "print(rdd_forum_events_parsed.count())\n",
    "print(rdd_forum_events_parsed.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556201\n",
      "{'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b', 'Title': 'Functional Sets / Functional Sets', 'Date': Timestamp('2013-04-17 17:47:58'), 'EventSubType': 'Check', 'ProblemType': 'Assignment', 'Grade': 9.32999992371, 'EventType': 'Problem', 'TimeStamp': 1366220878, 'ProblemID': 6}\n"
     ]
    }
   ],
   "source": [
    "# Concatenantes all three table into one big table\n",
    "rdd_events = (rdd_problem_events_parsed\n",
    "    .union(rdd_video_events_parsed)\n",
    "    .union(rdd_forum_events_parsed)\n",
    ")\n",
    "rdd_events.persist()\n",
    "print(rdd_events.count())\n",
    "print(rdd_events.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing meta data\n",
    "The goal is to have the table linking VideoIDs to corresponding ProblemIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments = sorted((rdd_problem_events_parsed\n",
    "    .map(lambda x: (x['ProblemID'],x['Title']))\n",
    "    .distinct()\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd_video_info = sc.textFile(\"data/\"+config['session']+\"_Video_Info.csv\")\n",
    "videos = sorted((rdd_video_info\n",
    "    .map(lambda x: x.split(','))\n",
    "    .filter(lambda x: not x[1] in ['None', 'OpenTime'] )\n",
    "    .map(lambda x: (int(x[7]),x[2]))\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: [35, 37, 39, 41, 43, 47, 49],\n",
       " 7: [3, 4, 5, 6, 7, 8, 33],\n",
       " 12: [51, 53, 75],\n",
       " 14: [71, 81, 85, 79, 87, 77],\n",
       " 17: [109, 105, 115, 107, 103, 113, 111],\n",
       " 20: [123, 117, 125, 121, 127, 119]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Made by hand... so painful\n",
    "LECTURES_PER_PROBLEM = {\n",
    "    7: [3,4,5,6,7,8,33], # Lecture 1\n",
    "    6: [35,37,39,41,43,47,49], # Lecture 2\n",
    "    12: [51,53,75], # Lecture 3\n",
    "    14: [71,81,85,79,87,77], # Lecture 4\n",
    "    17: [109,105,115,107,103,113,111], # Lecture 6\n",
    "    20: [123,117,125,121,127,119] # Lecture 7\n",
    "}\n",
    "LECTURES_PER_PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{51: 12, 3: 7, 4: 7, 49: 6, 6: 7, 7: 7, 8: 7, 119: 20, 77: 14, 79: 14, 43: 6, 75: 12, 85: 14, 87: 14, 39: 6, 71: 14, 111: 17, 81: 14, 5: 7, 33: 7, 35: 6, 37: 6, 103: 17, 105: 17, 107: 17, 109: 17, 47: 6, 113: 17, 53: 12, 115: 17, 117: 20, 41: 6, 121: 20, 123: 20, 125: 20, 127: 20}\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_PER_LECTURE = {}\n",
    "for pb in LECTURES_PER_PROBLEM.keys():\n",
    "    for lc in LECTURES_PER_PROBLEM[pb]:\n",
    "        PROBLEM_PER_LECTURE[lc]=pb\n",
    "print(PROBLEM_PER_LECTURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping & Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 24626\n"
     ]
    }
   ],
   "source": [
    "# uses the function groupByKey on our events with the key 'SessionStudentID'\n",
    "rdd_events_by_students = (rdd_events\n",
    "    .map(lambda x: (x['SessionUserID'],x))\n",
    "    # Groups the list of event by student\n",
    "    .groupByKey()\n",
    "    # Sorts each student sequence by the timestamp\n",
    "    .map(lambda x: (x[0],sorted(x[1], key=(lambda event: event['TimeStamp']))))\n",
    ")\n",
    "rdd_events_by_students.persist()\n",
    "print(\"Number of students: %d\" % rdd_events_by_students.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to have a friendly way to print the events\n",
    "def eventToString(event):\n",
    "    return {\n",
    "        \"Problem\": lambda x: \"(P \"+str(event['ProblemID'])+\")\",\n",
    "        \"Video\": lambda x: \"(V \"+str(event['VideoID'])+\")\",\n",
    "        \"Forum\": lambda x: \"(F)\"\n",
    "    }[event['EventType']](event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_STUDENTS={\n",
    "    '6ea6949ca133acede360d3573f9d1168b3d70b51':'very good student',\n",
    "    '3b305429f93de02637949578a5f9e23f13eb0726':'did two problems',\n",
    "    '865981d5b40a693bafbadae4b1df769be03a25c3':'watched 8 videos',\n",
    "    '67cdae6073d1089b695e2a615a01187586ad7ba6':'normal student',\n",
    "    'fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f':'the very best student',\n",
    "    '295b3496278626b6d337812b1882b756336fd633':'whatdup with this guy?'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6ea6949ca133acede360d3573f9d1168b3d70b51 : very good student\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 6) (V 6) (V 6) (V 6) (V 6) (V 7) (V 7) (V 7) (V 33) (V 33) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) (V 51) (V 51) (V 51) (V 53) (V 53) (V 53) (V 75) (V 75) (V 75) (V 75) (P 12) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (V 73) (V 89) (V 91) (V 93) (V 95) (V 95) (V 97) (V 101) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (V 109) (V 111) (V 113) (V 107) (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (F) (F) (P 20) (F) (F) (V 125) (V 125) (P 20) (F) \n",
      "\n",
      " 865981d5b40a693bafbadae4b1df769be03a25c3 : watched 8 videos\n",
      "(V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 7) (V 33) (V 35) (V 35) (V 35) (V 35) \n",
      "\n",
      " 3b305429f93de02637949578a5f9e23f13eb0726 : did two problems\n",
      "(P 7) (P 6) \n",
      "\n",
      " fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f : the very best student\n",
      "(V 8) (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 7) (V 7) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 43) (V 47) (V 47) (V 47) (V 47) (V 47) (V 47) (V 49) (V 49) (F) (F) (F) (F) (F) (P 7) (P 7) (P 7) (F) (P 7) (P 7) (P 6) (P 6) (V 51) (V 51) (V 53) (V 53) (V 53) (V 53) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 53) (V 75) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (F) (F) (F) (F) (V 79) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (V 71) (P 12) (P 12) (P 12) (P 12) (V 73) (V 73) (V 73) (P 14) (P 14) (P 14) (P 14) (V 73) (V 89) (V 91) (V 91) (V 93) (V 95) (V 97) (V 101) (P 14) (V 103) (V 103) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 111) (V 111) (V 111) (V 111) (V 113) (V 113) (V 115) (V 115) (V 117) (V 119) (V 121) (V 121) (V 123) (P 17) (P 17) (V 125) (V 127) (P 17) (P 20) (P 20) (P 20) (P 17) (P 17) (P 17) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (P 17) \n",
      "\n",
      " 295b3496278626b6d337812b1882b756336fd633 : whatdup with this guy?\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 7) (V 33) (P 7) (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 47) (V 49) (P 6) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 89) (V 89) (V 89) (V 91) (V 91) (V 91) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 95) (V 95) (V 95) (V 95) (V 97) (V 97) (V 97) (V 101) (V 101) (V 101) (V 103) (V 103) (V 103) (V 105) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 109) (V 109) (V 111) (V 111) (V 111) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 115) (V 115) (V 121) (P 17) (P 17) (V 117) (V 117) (V 117) (V 117) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 121) (V 121) (V 121) (V 121) (V 121) (V 121) (V 123) (V 123) (V 123) (V 125) (V 125) (V 125) (V 125) (P 20) (V 127) \n",
      "\n",
      " 67cdae6073d1089b695e2a615a01187586ad7ba6 : normal student\n",
      "(V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) (F) (F) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 87) (V 71) (P 14) (P 12) (P 12) (P 17) (P 20) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) \n"
     ]
    }
   ],
   "source": [
    "# Looks at the data for a few students\n",
    "for studentID,events in rdd_events_by_students.filter(lambda x: x[0] in TEST_STUDENTS.keys()).collect():\n",
    "    print('\\n',studentID,':',TEST_STUDENTS[studentID])\n",
    "    for event in events:\n",
    "        print(eventToString(event), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting learning patterns\n",
    "The goal is to extract what a students does between a failed attempt at an assignment and a successful attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The goal is to extract the list corresponding to each Problem\n",
    "def extractPatterns(events):\n",
    "    patterns = {}\n",
    "    for problemID in LECTURES_PER_PROBLEM.keys():\n",
    "        patterns[problemID]=[]\n",
    "    # for each problem measure first and last entry\n",
    "    for event in events:\n",
    "        if event['EventType']=='Problem':\n",
    "            patterns[event['ProblemID']].append(event)\n",
    "        if event['EventType']=='Video':\n",
    "            if event['VideoID'] in PROBLEM_PER_LECTURE.keys():\n",
    "                patterns[PROBLEM_PER_LECTURE[event['VideoID']]].append(event)\n",
    "    return patterns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal is to concatenate small sub events into one big event\n",
    "# For example Play/Pause/Play/Pause/Play/Pause on a video counts as only a Video event\n",
    "def eventConcat(events):\n",
    "    if len(events)<2:\n",
    "        return events\n",
    "    res=[events[0]]\n",
    "    for event in events[1:]:\n",
    "        if (\n",
    "            event['EventType']!=res[-1]['EventType'] \n",
    "            or event.get('VideoID',None)!=res[-1].get('VideoID',None)\n",
    "            or event['EventType']=='Problem'\n",
    "        ):\n",
    "            res.append(event)\n",
    "    return res\n",
    "\n",
    "def patternsConcat(patterns):\n",
    "    res = {}\n",
    "    for pattern in patterns.keys():\n",
    "        res[pattern]=eventConcat(patterns[pattern])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ea6949ca133acede360d3573f9d1168b3d70b51 very good student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (V 109) (V 111) (V 113) (V 107) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (P 20) (V 125) (P 20) \n",
      "\n",
      "865981d5b40a693bafbadae4b1df769be03a25c3 watched 8 videos\n",
      "6\t>>>  (V 35) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "3b305429f93de02637949578a5f9e23f13eb0726 did two problems\n",
      "6\t>>>  (P 6) \n",
      "7\t>>>  (P 7) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f the very best student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 33) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (P 20) (P 20) (P 20) \n",
      "\n",
      "295b3496278626b6d337812b1882b756336fd633 whatdup with this guy?\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) \n",
      "20\t>>>  (V 121) (V 117) (V 119) (V 121) (V 123) (V 125) (P 20) (V 127) \n",
      "\n",
      "67cdae6073d1089b695e2a615a01187586ad7ba6 normal student\n",
      "6\t>>>  (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) \n",
      "7\t>>>  (V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) \n",
      "17\t>>>  (P 17) \n",
      "20\t>>>  (P 20) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd_events_by_students_extract = (rdd_events_by_students\n",
    "    # x = (studentID,eventList)\n",
    "    .map(lambda x: (x[0],extractPatterns(x[1])))\n",
    "    # x = (studentID,{problemID:pattern,...})\n",
    "    .map(lambda x: (x[0],patternsConcat(x[1])))\n",
    ")\n",
    "\n",
    "rdd_events_by_students_extract.persist()\n",
    "\n",
    "# Looks at the data for a student, now that it's sorted by TimeStamps\n",
    "def displayStudentsPatterns(rdd,students):\n",
    "    for studentID,patterns in rdd.filter(lambda x:x[0] in students.keys()).collect():\n",
    "        print(studentID, students[studentID])\n",
    "        for pb in sorted(patterns.keys()):\n",
    "            print(pb,end='\\t>>>  ')\n",
    "            for event in patterns[pb]:\n",
    "                print(eventToString(event), end=\" \")\n",
    "            print()\n",
    "        print()\n",
    "\n",
    "displayStudentsPatterns(rdd_events_by_students_extract,TEST_STUDENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VVVVVVVVVVVP\n",
      "VVVVVVVP\n",
      "VVVP\n",
      "VVVVP\n",
      "VVVVPP\n",
      "PP\n",
      "P\n",
      "VVVVP\n",
      "VVVVVVVP\n",
      "VVVVVVVP\n"
     ]
    }
   ],
   "source": [
    "def eventToString(event,verbosity):\n",
    "    if verbosity == 'minimal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\",\n",
    "            \"Video\": lambda x:\"V\",\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    if verbosity == 'normal':\n",
    "        out = {\n",
    "            \"Problem\": lambda x:\"P\"+str(x['ProblemID']),\n",
    "            \"Video\": lambda x:\"V\"+str(x['VideoID']),\n",
    "            \"Forum\": lambda x:\"F\",\n",
    "        }\n",
    "    return out[event['EventType']](event)\n",
    "\n",
    "def patternToString(pattern,verbosity):\n",
    "    link = \"\" if verbosity == 'minimal' else \"-\"\n",
    "    return link.join([eventToString(event,verbosity) for event in pattern])\n",
    "\n",
    "def containsProblem(pattern):\n",
    "    return 'P' in patternToString(pattern,'minimal')\n",
    "\n",
    "def getBeforeLastProblem(pattern):\n",
    "    indexOfLastProblem = patternToString(pattern,'minimal').rfind('P')\n",
    "    return pattern[:(indexOfLastProblem+1)]\n",
    "\n",
    "def getBeforeFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[:indexOfFirstProblem]\n",
    "\n",
    "def getAfterFirstProblem(pattern):\n",
    "    indexOfFirstProblem = patternToString(pattern,'minimal').find('P')\n",
    "    return pattern[indexOfFirstProblem:]\n",
    "\n",
    "# Uses the method flatMap on the students patterns table to have a table of all the patterns\n",
    "rdd_patterns = (rdd_events_by_students_extract\n",
    "    # x = (studentID,{problemID:pattern,...})\n",
    "    .flatMap(lambda x: [\n",
    "        (pb,x[1][pb]) for pb in x[1].keys() \n",
    "    ])\n",
    "    # x = (problemID,pattern)\n",
    "    .filter(lambda x: containsProblem(x[1]))\n",
    "    # x = (problemID,pattern)\n",
    "    .map(lambda x: (x[0],getBeforeLastProblem(x[1])))\n",
    ")\n",
    "\n",
    "rdd_patterns.persist()\n",
    "for pattern in rdd_patterns.map(lambda x: patternToString(x[1],'minimal')).take(10):\n",
    "    print (pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem 6\n",
      "pattern V35-V37-V39-V41-V43-V35-V41-V43-V47-V49-V37-P6\n",
      "{   'firstProblemGrade': 10.0,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 10.0,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.08333333333333333,\n",
      "    'repeatedVideoBeforeFirstProblem': 1.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0.0,\n",
      "    'timeBetweenStartAndFirstProblem': 0.0,\n",
      "    'timeBetweenStartAndLastProblem': 0.0,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 11,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 7\n",
      "pattern V8-V3-V4-V5-V6-V7-V33-P7\n",
      "{   'firstProblemGrade': 10.0,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 10.0,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.125,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0.0,\n",
      "    'timeBetweenStartAndFirstProblem': 0.0,\n",
      "    'timeBetweenStartAndLastProblem': 0.0,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 7,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 12\n",
      "pattern V51-V53-V75-P12\n",
      "{   'firstProblemGrade': 7.82000017166,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 7.82000017166,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.25,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0.0,\n",
      "    'timeBetweenStartAndFirstProblem': 0.0,\n",
      "    'timeBetweenStartAndLastProblem': 0.0,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 3,\n",
      "    'watchedAllVideosBeforeFirstProblem': 1.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 14\n",
      "pattern V79-V77-V81-V85-P14\n",
      "{   'firstProblemGrade': 9.05000019073,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 9.05000019073,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.2,\n",
      "    'repeatedVideoBeforeFirstProblem': 0.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0.0,\n",
      "    'timeBetweenStartAndFirstProblem': 0.0,\n",
      "    'timeBetweenStartAndLastProblem': 0.0,\n",
      "    'totalNumberOfProblemSubmissions': 1,\n",
      "    'totalNumberOfVideoWatched': 4,\n",
      "    'watchedAllVideosBeforeFirstProblem': 0.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n",
      "problem 6\n",
      "pattern V47-V39-V37-V39-P6-P6\n",
      "{   'firstProblemGrade': 8.67000007629,\n",
      "    'increaseGradeFromFirstToLastProblem': 0.0,\n",
      "    'lastProblemGrade': 8.67000007629,\n",
      "    'percentageImprovedBetweenFirstAndLastProblem': 0.0,\n",
      "    'proportionOfProblemEvents': 0.3333333333333333,\n",
      "    'repeatedVideoBeforeFirstProblem': 1.0,\n",
      "    'timeBetweenFirstAndLastProblem': 0.0,\n",
      "    'timeBetweenStartAndFirstProblem': 0.0,\n",
      "    'timeBetweenStartAndLastProblem': 0.0,\n",
      "    'totalNumberOfProblemSubmissions': 2,\n",
      "    'totalNumberOfVideoWatched': 4,\n",
      "    'watchedAllVideosBeforeFirstProblem': 0.0,\n",
      "    'watchedSomeVideoAfterFirstProblem': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getFeatures(problem, pattern):\n",
    "    features = {}\n",
    "    \n",
    "    videoBeforeFirstProblem = [video['VideoID'] for video in getBeforeFirstProblem(pattern)]\n",
    "    value = 0. if False in [(videoID in videoBeforeFirstProblem) for videoID in LECTURES_PER_PROBLEM[problem]] else 1. \n",
    "    features['watchedAllVideosBeforeFirstProblem'] = value\n",
    "\n",
    "    value = 1. if len(videoBeforeFirstProblem) != len(set(videoBeforeFirstProblem)) else 0.\n",
    "    features['repeatedVideoBeforeFirstProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Video' for event in pattern])\n",
    "    features['totalNumberOfVideoWatched'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])\n",
    "    features['totalNumberOfProblemSubmissions'] = value \n",
    "            \n",
    "    value = 1. if [v for v in getAfterFirstProblem(pattern) if v['EventType']=='Video'] else 0.\n",
    "    features['watchedSomeVideoAfterFirstProblem'] = value\n",
    "\n",
    "    grades = [problem['Grade'] for problem in pattern if problem['EventType']=='Problem']\n",
    "    value = 1. if grades[-1] > grades[0] else 0.\n",
    "    features['increaseGradeFromFirstToLastProblem'] = value\n",
    "\n",
    "    value = sum([event['EventType']=='Problem' for event in pattern])/len(pattern)\n",
    "    features['proportionOfProblemEvents'] = value\n",
    "    \n",
    "    value = 0.\n",
    "    features['timeBetweenStartAndFirstProblem'] = value\n",
    "    \n",
    "    value = 0.\n",
    "    features['timeBetweenStartAndLastProblem'] = value\n",
    "    \n",
    "    value = 0.\n",
    "    features['timeBetweenFirstAndLastProblem'] = value\n",
    "    \n",
    "    value = grades[0]\n",
    "    features['firstProblemGrade'] = value\n",
    "    \n",
    "    value = grades[-1]\n",
    "    features['lastProblemGrade'] = value\n",
    "    \n",
    "    value = 0.\n",
    "    features['percentageImprovedBetweenFirstAndLastProblem'] = value\n",
    "        \n",
    "    return(features)\n",
    "\n",
    "\n",
    "FEATURES = [\n",
    "    'watchedAllVideosBeforeFirstProblem',\n",
    "    'repeatedVideoBeforeFirstProblem',\n",
    "    'totalNumberOfVideoWatched',\n",
    "    'totalNumberOfProblemSubmissions',\n",
    "    'watchedSomeVideoAfterFirstProblem',\n",
    "    'increaseGradeFromFirstToLastProblem',\n",
    "    'proportionOfProblemEvents',\n",
    "    'timeBetweenStartAndFirstProblem',\n",
    "    'firstProblemGrade',\n",
    "    'lastProblemGrade',\n",
    "    'percentageImprovedBetweenFirstAndLastProblem'\n",
    "]\n",
    "\n",
    "rdd_pattern_features = (rdd_patterns\n",
    "    # x = (problemID, pattern)\n",
    "    .map(lambda x: (\n",
    "        x[0],\n",
    "        patternToString(x[1],'normal'),\n",
    "        getFeatures(x[0], x[1])\n",
    "    ))\n",
    ")\n",
    "\n",
    "rdd_pattern_features.persist()\n",
    "for featureVector in rdd_pattern_features.take(5):\n",
    "    print('problem', featureVector[0])\n",
    "    print('pattern', featureVector[1])\n",
    "    pp.pprint(featureVector[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
