{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA - Project\n",
    "## With Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(\"local[*]\", \"ADA\")\n",
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize(range(100))\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you received 4950 as a result, your spark is working well :) Good job !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"session\":\"progfun-002\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PROBLEM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 MaximumSubmissions / 3 AccountUserID / 4 SubmissionNumber / 5 Grade / 6 TimeStamp / 7 DataPackageID / 8 ProblemID / 9 SoftCloseTime / 10 ProblemType / 11 HardCloseTime / 12 Platform / 13 OpenTime / 14 EventType / 15 Title / 16 SessionUserID / 17 UniqueProblemID / 18 UniqueUserID / \n",
      "\n",
      "--- VIDEO_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 OldTime / 3 AccountUserID / 4 CurrentTime / 5 SeekType / 6 TimeStamp / 7 DataPackageID / 8 UniqueRowID / 9 TableName / 10 VideoID / 11 Platform / 12 NewSpeed / 13 EventSource / 14 EventType / 15 SessionUserID / 16 NewTime / 17 OldSpeed / \n",
      "\n",
      "--- FORUM_EVENTS ---\n",
      "0 EventID / 1 ForumUserID / 2 PostID / 3 AccountUserID / 4 TimeStamp / 5 DataPackageID / 6 UniqueRowID / 7 TableName / 8 Platform / 9 EventSource / 10 PostType / 11 EventType / 12 JoinID / 13 SessionUserID / "
     ]
    }
   ],
   "source": [
    "# Reading csv files: Create RDD () with one string entry per line in the file\n",
    "rdd_problem_events = sc.textFile(\"data/\"+config['session']+\"_Problem_Events_with_Info.csv\")\n",
    "rdd_video_events = sc.textFile(\"data/\"+config['session']+\"_Video_Events.csv\")\n",
    "rdd_forum_events = sc.textFile(\"data/\"+config['session']+\"_Forum_Events.csv\")\n",
    "\n",
    "# Prints the first line (header) along with indices for each table\n",
    "print(\"--- PROBLEM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_problem_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- VIDEO_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_video_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")\n",
    "\n",
    "print(\"\\n\\n--- FORUM_EVENTS ---\")\n",
    "for idx,field in enumerate(rdd_forum_events.first().split(\",\")): \n",
    "    print(idx,field, end=\" / \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bcd1a54ed6ddb04b4a6fb2906110a01,None,0,None,7,None,1365344171,progfun-002,7,2147483640,Video,2147483640,Coursera,32400,Problem.Check,Lecture 1.2 - Elements of Programming (14:25),c4d4e5fcd2feba9f3234ee8d852dc7b22fbc07e4,f322944718b2ee0e53292118111533c7,21f13b3f6b50a83343b57d2f1d07dbdf \n",
      "\n",
      "db75adce6b87e7ab79242ea0af4b82d4,None,154.696,None,154.697,None,1372391638,progfun-002,00000078c0f0685cc50a25a8d5734a88,Video_Events,33,coursera,1.0,None,Video.Play,ef64fb7b096008f7eaf8441684afdf99af9af54a,None,1.0 \n",
      "\n",
      "f3fdb52859b2511308aee554a573194e,None,17,4108315,1376254235,progfun-002,000006c12322ca29c7013dac42ef1a6a,Forum_Events,coursera,None,Thread,Forum.Thread.View,03b1fa287de5ef57d9c8482195b5167f,None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the filter method to remove the first line\n",
    "rdd_problem_events = rdd_problem_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_video_events = rdd_video_events.filter(lambda x: not x.startswith('EventID'))\n",
    "rdd_forum_events = rdd_forum_events.filter(lambda x: not x.startswith('EventID'))\n",
    "\n",
    "# Prints first record for each table\n",
    "print(rdd_problem_events.first(),\"\\n\") \n",
    "print(rdd_video_events.first(),\"\\n\") \n",
    "print(rdd_forum_events.first(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to parse the string entries from previous dataset\n",
    "def parse_problems(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'Grade':float(data[5]),\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'ProblemID':int(data[8]),\n",
    "        'ProblemType':data[10],\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'Title':data[15],\n",
    "        'SessionUserID':data[16]\n",
    "    }\n",
    "\n",
    "def parse_videos(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'TimeStamp':int(data[6]),\n",
    "        'Date':pd.to_datetime(int(data[6]),unit='s'),\n",
    "        'VideoID':int(data[10]),\n",
    "        'EventType':data[14].split('.')[0],\n",
    "        'EventSubType':data[14].split('.')[1],\n",
    "        'SessionUserID':data[15]\n",
    "    }\n",
    "\n",
    "def parse_forums(x):\n",
    "    data = x.split(',')\n",
    "    return {\n",
    "        'AccountUserID':data[3],\n",
    "        'TimeStamp':int(data[4]),\n",
    "        'Date':pd.to_datetime(int(data[4]),unit='s'),\n",
    "        'EventType':data[11].split('.')[0],\n",
    "        'EventSubType':data[11].split('.')[1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to filter the string entries from previous dataset\n",
    "def filter_problems(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # Some problem event are quiz inside video, we decide to not consider these\n",
    "        (data[10]=='Assignment')\n",
    "        # We remove IDs of assignments that have been used by the teaching staff for testing the platform\n",
    "        and (not data[8] in ['1','2','3','4','5'])\n",
    "        # Discard assignments with no grade\n",
    "        and (not data[5] in ['None'])\n",
    "    )\n",
    "\n",
    "def filter_videos(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        # We remove video that do not belong to the MOOC lectures or ar just Setup videos\n",
    "        (data[10] not in ['9','12','11','10','13','2','29','25','21','27','23'])\n",
    "        # Keeps only \"Play\" EnventSubStype for videos (makes difference between opening the page or starting the video)\n",
    "        and (data[14].split('.')[1] in ['Play','Load'])\n",
    "    )\n",
    "\n",
    "def filter_forums(x):\n",
    "    data = x.split(',')\n",
    "    return (\n",
    "        True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90325\n",
      "{'EventSubType': 'Check', 'Date': Timestamp('2013-04-17 17:47:58'), 'ProblemType': 'Assignment', 'TimeStamp': 1366220878, 'ProblemID': 6, 'Title': 'Functional Sets / Functional Sets', 'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b', 'EventType': 'Problem', 'Grade': 9.32999992371} \n",
      "\n",
      "1168226\n",
      "{'EventSubType': 'Play', 'Date': Timestamp('2013-06-28 03:53:58'), 'TimeStamp': 1372391638, 'VideoID': 33, 'SessionUserID': 'ef64fb7b096008f7eaf8441684afdf99af9af54a', 'EventType': 'Video'} \n",
      "\n",
      "297650\n",
      "{'AccountUserID': '4108315', 'EventSubType': 'Thread', 'Date': Timestamp('2013-08-11 20:50:35'), 'TimeStamp': 1376254235, 'EventType': 'Forum'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the map method to have more workable data\n",
    "rdd_problem_events_parsed = rdd_problem_events.filter(filter_problems).map(parse_problems)\n",
    "rdd_video_events_parsed = rdd_video_events.filter(filter_videos).map(parse_videos)\n",
    "rdd_forum_events_parsed = rdd_forum_events.filter(filter_forums).map(parse_forums)\n",
    "\n",
    "# Prints the count of elements along with the first element of each table\n",
    "print(rdd_problem_events_parsed.count())\n",
    "print(rdd_problem_events_parsed.first(),\"\\n\") \n",
    "print(rdd_video_events_parsed.count()) \n",
    "print(rdd_video_events_parsed.first(),\"\\n\") \n",
    "print(rdd_forum_events_parsed.count()) \n",
    "print(rdd_forum_events_parsed.first(),\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForumUserID,AccountUserID,DataPackageID,UniqueRowID,TableName,Platform,SessionUserID \n",
      "\n",
      "297650\n",
      "{'AccountUserID': '2009208', 'EventSubType': 'Thread', 'Date': Timestamp('2013-05-09 20:22:34'), 'TimeStamp': 1368130954, 'SessionUserID': '16e564ed1e9b7104acde8f075c26a1872695fb5e', 'EventType': 'Forum'}\n"
     ]
    }
   ],
   "source": [
    "# Handles bug with the forum events table having 'AccountUserID' instead of 'SessionUserID'\n",
    "# Using the table progfun-002_User_Hash_Mapping\n",
    "rdd_user_mapping = sc.textFile(\"data/\"+config['session']+\"_User_Hash_Mapping.csv\")\n",
    "print(rdd_user_mapping.take(1)[0],\"\\n\")\n",
    "\n",
    "def f(x):\n",
    "    x[1][1]['SessionUserID']=x[1][0] \n",
    "    return x[1][1]\n",
    "\n",
    "rdd_forum_events_parsed = (rdd_user_mapping\n",
    "    # removes header\n",
    "    .filter(lambda x: not x.startswith(\"ForumUserID\"))\n",
    "    # maps to have the format (Key=AccountUserID,Value=SessionUserID)\n",
    "    .map(lambda x:(x.split(\",\")[1],x.split(\",\")[6]))\n",
    "    # join with rdd_forum_event to get format (map to have the (Key=AccountUserID,Value=(SessionUserID,EventObject)) format)\n",
    "    .join(rdd_forum_events_parsed\n",
    "        # map to have the (Key=AccountUserID,Value=EventObject) format\n",
    "        .map(lambda x: (x['AccountUserID'],x))\n",
    "    )\n",
    "    # Use the function f to update EventObject with the joined SessionUserID\n",
    "    .map(f)\n",
    ")\n",
    "\n",
    "print(rdd_forum_events_parsed.count())\n",
    "print(rdd_forum_events_parsed.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556201\n",
      "{'Grade': 9.32999992371, 'Date': Timestamp('2013-04-17 17:47:58'), 'ProblemType': 'Assignment', 'TimeStamp': 1366220878, 'EventSubType': 'Check', 'Title': 'Functional Sets / Functional Sets', 'ProblemID': 6, 'EventType': 'Problem', 'SessionUserID': 'd8f79efa32a560b8a46ea2b12d9bed97c9e39b4b'}\n"
     ]
    }
   ],
   "source": [
    "# Concatenantes all three table into one big table\n",
    "rdd_events = (rdd_problem_events_parsed\n",
    "    .union(rdd_video_events_parsed)\n",
    "    .union(rdd_forum_events_parsed)\n",
    ")\n",
    "rdd_events.persist()\n",
    "print(rdd_events.count())\n",
    "print(rdd_events.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing meta data\n",
    "The goal is to have the table linking VideoIDs to corresponding ProblemIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments = sorted((rdd_problem_events_parsed\n",
    "    .map(lambda x: (x['ProblemID'],x['Title']))\n",
    "    .distinct()\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd_video_info = sc.textFile(\"data/\"+config['session']+\"_Video_Info.csv\")\n",
    "videos = sorted((rdd_video_info\n",
    "    .map(lambda x: x.split(','))\n",
    "    .filter(lambda x: not x[1] in ['None', 'OpenTime'] )\n",
    "    .map(lambda x: (int(x[7]),x[2]))\n",
    "    .collect()\n",
    "),key=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: [35, 37, 39, 41, 43, 47, 49],\n",
       " 7: [3, 4, 5, 6, 7, 8, 33],\n",
       " 12: [51, 53, 75],\n",
       " 14: [71, 81, 85, 79, 87, 77],\n",
       " 17: [109, 105, 115, 107, 103, 113, 111],\n",
       " 20: [123, 117, 125, 121, 127, 119]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Made by hand... so painful\n",
    "LECTURES_PER_PROBLEM = {\n",
    "    7: [3,4,5,6,7,8,33], # Lecture 1\n",
    "    6: [35,37,39,41,43,47,49], # Lecture 2\n",
    "    12: [51,53,75], # Lecture 3\n",
    "    14: [71,81,85,79,87,77], # Lecture 4\n",
    "    17: [109,105,115,107,103,113,111], # Lecture 6\n",
    "    20: [123,117,125,121,127,119] # Lecture 7\n",
    "}\n",
    "LECTURES_PER_PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{51: 12, 3: 7, 4: 7, 49: 6, 6: 7, 7: 7, 8: 7, 119: 20, 77: 14, 79: 14, 43: 6, 75: 12, 85: 14, 87: 14, 39: 6, 71: 14, 111: 17, 81: 14, 5: 7, 33: 7, 35: 6, 37: 6, 103: 17, 105: 17, 107: 17, 109: 17, 47: 6, 113: 17, 53: 12, 115: 17, 117: 20, 41: 6, 121: 20, 123: 20, 125: 20, 127: 20}\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_PER_LECTURE = {}\n",
    "for pb in LECTURES_PER_PROBLEM.keys():\n",
    "    for lc in LECTURES_PER_PROBLEM[pb]:\n",
    "        PROBLEM_PER_LECTURE[lc]=pb\n",
    "print(PROBLEM_PER_LECTURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping & Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 24626\n"
     ]
    }
   ],
   "source": [
    "# uses the function groupByKey on our events with the key 'SessionStudentID'\n",
    "rdd_events_by_students = (rdd_events\n",
    "    .map(lambda x: (x['SessionUserID'],x))\n",
    "    # Groups the list of event by student\n",
    "    .groupByKey()\n",
    "    # Sorts each student sequence by the timestamp\n",
    "    .map(lambda x: (x[0],sorted(x[1], key=(lambda event: event['TimeStamp']))))\n",
    ")\n",
    "rdd_events_by_students.persist()\n",
    "print(\"Number of students: %d\" % rdd_events_by_students.count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to have a friendly way to print the events\n",
    "def eventToString(event):\n",
    "    return {\n",
    "        \"Problem\": lambda x: \"(P \"+str(event['ProblemID'])+\")\",\n",
    "        \"Video\": lambda x: \"(V \"+str(event['VideoID'])+\")\",\n",
    "        \"Forum\": lambda x: \"(F)\"\n",
    "    }[event['EventType']](event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_STUDENTS={\n",
    "    '6ea6949ca133acede360d3573f9d1168b3d70b51':'very good student',\n",
    "    '3b305429f93de02637949578a5f9e23f13eb0726':'did two problems',\n",
    "    '865981d5b40a693bafbadae4b1df769be03a25c3':'watched 8 videos',\n",
    "    '67cdae6073d1089b695e2a615a01187586ad7ba6':'normal student',\n",
    "    'fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f':'the very best student',\n",
    "    '295b3496278626b6d337812b1882b756336fd633':'whatdup with this guy?'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6ea6949ca133acede360d3573f9d1168b3d70b51 : very good student\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 6) (V 6) (V 6) (V 6) (V 6) (V 7) (V 7) (V 7) (V 33) (V 33) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) (V 51) (V 51) (V 51) (V 53) (V 53) (V 53) (V 75) (V 75) (V 75) (V 75) (P 12) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (V 73) (V 89) (V 91) (V 93) (V 95) (V 95) (V 97) (V 101) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (V 109) (V 111) (V 113) (V 107) (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (F) (F) (P 20) (F) (F) (V 125) (V 125) (P 20) (F) \n",
      "\n",
      " 865981d5b40a693bafbadae4b1df769be03a25c3 : watched 8 videos\n",
      "(V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 7) (V 33) (V 35) (V 35) (V 35) (V 35) \n",
      "\n",
      " 3b305429f93de02637949578a5f9e23f13eb0726 : did two problems\n",
      "(P 7) (P 6) \n",
      "\n",
      " fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f : the very best student\n",
      "(V 8) (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 7) (V 7) (V 33) (P 7) (V 35) (V 35) (V 35) (V 35) (V 37) (V 37) (V 37) (V 39) (V 39) (V 39) (V 39) (V 41) (V 41) (V 43) (V 43) (V 47) (V 47) (V 47) (V 47) (V 47) (V 47) (V 49) (V 49) (F) (F) (F) (F) (F) (P 7) (P 7) (P 7) (F) (P 7) (P 7) (P 6) (P 6) (V 51) (V 51) (V 53) (V 53) (V 53) (V 53) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 53) (V 75) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (F) (F) (F) (F) (V 79) (V 79) (V 77) (V 81) (V 83) (V 85) (V 87) (V 71) (V 71) (P 12) (P 12) (P 12) (P 12) (V 73) (V 73) (V 73) (P 14) (P 14) (P 14) (P 14) (V 73) (V 89) (V 91) (V 91) (V 93) (V 95) (V 97) (V 101) (P 14) (V 103) (V 103) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 111) (V 111) (V 111) (V 111) (V 113) (V 113) (V 115) (V 115) (V 117) (V 119) (V 121) (V 121) (V 123) (P 17) (P 17) (V 125) (V 127) (P 17) (P 20) (P 20) (P 20) (P 17) (P 17) (P 17) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 7) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (P 17) (P 17) \n",
      "\n",
      " 295b3496278626b6d337812b1882b756336fd633 : whatdup with this guy?\n",
      "(V 8) (V 3) (V 3) (V 4) (V 5) (V 5) (V 6) (V 7) (V 33) (P 7) (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 47) (V 49) (P 6) (V 51) (V 51) (V 51) (V 51) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 73) (V 89) (V 89) (V 89) (V 91) (V 91) (V 91) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 93) (V 95) (V 95) (V 95) (V 95) (V 97) (V 97) (V 97) (V 101) (V 101) (V 101) (V 103) (V 103) (V 103) (V 105) (V 105) (V 105) (V 107) (V 107) (V 107) (V 107) (V 109) (V 109) (V 109) (V 109) (V 111) (V 111) (V 111) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 113) (V 115) (V 115) (V 121) (P 17) (P 17) (V 117) (V 117) (V 117) (V 117) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 119) (V 121) (V 121) (V 121) (V 121) (V 121) (V 121) (V 123) (V 123) (V 123) (V 125) (V 125) (V 125) (V 125) (P 20) (V 127) \n",
      "\n",
      " 67cdae6073d1089b695e2a615a01187586ad7ba6 : normal student\n",
      "(V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) (F) (F) (V 51) (V 53) (V 75) (P 12) (P 12) (V 79) (V 77) (V 81) (V 83) (V 83) (V 85) (V 87) (V 87) (V 71) (P 14) (P 12) (P 12) (P 17) (P 20) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) (F) \n"
     ]
    }
   ],
   "source": [
    "# Looks at the data for a few students\n",
    "for studentID,events in rdd_events_by_students.filter(lambda x: x[0] in TEST_STUDENTS.keys()).collect():\n",
    "    print('\\n',studentID,':',TEST_STUDENTS[studentID])\n",
    "    for event in events:\n",
    "        print(eventToString(event), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting learning patterns\n",
    "The goal is to extract what a students does between a failed attempt at an assignment and a successful attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The goal is to extract the list corresponding to each Problem\n",
    "def extractPatterns(events):\n",
    "    patterns = {}\n",
    "    for problemID in LECTURES_PER_PROBLEM.keys():\n",
    "        patterns[problemID]=[]\n",
    "    # for each problem measure first and last entry\n",
    "    for event in events:\n",
    "        if event['EventType']=='Problem':\n",
    "            patterns[event['ProblemID']].append(event)\n",
    "        if event['EventType']=='Video':\n",
    "            if event['VideoID'] in PROBLEM_PER_LECTURE.keys():\n",
    "                patterns[PROBLEM_PER_LECTURE[event['VideoID']]].append(event)\n",
    "    return patterns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal is to concatenate small sub events into one big event\n",
    "# For example Play/Pause/Play/Pause/Play/Pause on a video counts as only a Video event\n",
    "def eventConcat(events):\n",
    "    if len(events)<2:\n",
    "        return events\n",
    "    res=[events[0]]\n",
    "    for event in events[1:]:\n",
    "        if (\n",
    "            event['EventType']!=res[-1]['EventType'] \n",
    "            or event.get('VideoID',None)!=res[-1].get('VideoID',None)\n",
    "            or event['EventType']=='Problem'\n",
    "        ):\n",
    "            res.append(event)\n",
    "    return res\n",
    "\n",
    "def patternsConcat(patterns):\n",
    "    res = {}\n",
    "    for pattern in patterns.keys():\n",
    "        res[pattern]=eventConcat(patterns[pattern])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ea6949ca133acede360d3573f9d1168b3d70b51 very good student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (V 109) (V 111) (V 113) (V 107) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (V 125) (P 20) (V 125) (P 20) \n",
      "\n",
      "865981d5b40a693bafbadae4b1df769be03a25c3 watched 8 videos\n",
      "6\t>>>  (V 35) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "3b305429f93de02637949578a5f9e23f13eb0726 did two problems\n",
      "6\t>>>  (P 6) \n",
      "7\t>>>  (P 7) \n",
      "12\t>>>  \n",
      "14\t>>>  \n",
      "17\t>>>  \n",
      "20\t>>>  \n",
      "\n",
      "fb4c81b3df430d1f0fbb8d0ca3e470ac6bf92a2f the very best student\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 4) (V 6) (V 7) (V 33) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) (P 17) \n",
      "20\t>>>  (V 117) (V 119) (V 121) (V 123) (V 125) (V 127) (P 20) (P 20) (P 20) \n",
      "\n",
      "295b3496278626b6d337812b1882b756336fd633 whatdup with this guy?\n",
      "6\t>>>  (V 35) (V 37) (V 39) (V 41) (V 43) (V 47) (V 49) (P 6) \n",
      "7\t>>>  (V 8) (V 3) (V 4) (V 5) (V 6) (V 7) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) (P 14) (P 14) (P 14) \n",
      "17\t>>>  (V 103) (V 105) (V 107) (V 109) (V 111) (V 113) (V 115) (P 17) (P 17) \n",
      "20\t>>>  (V 121) (V 117) (V 119) (V 121) (V 123) (V 125) (P 20) (V 127) \n",
      "\n",
      "67cdae6073d1089b695e2a615a01187586ad7ba6 normal student\n",
      "6\t>>>  (V 35) (V 37) (V 41) (P 6) (V 43) (V 47) (V 49) (V 39) \n",
      "7\t>>>  (V 8) (V 6) (V 7) (V 6) (V 3) (V 4) (V 5) (V 33) (V 6) (V 33) (P 7) \n",
      "12\t>>>  (V 51) (V 53) (V 75) (P 12) (P 12) (P 12) (P 12) \n",
      "14\t>>>  (V 79) (V 77) (V 81) (V 85) (V 87) (V 71) (P 14) \n",
      "17\t>>>  (P 17) \n",
      "20\t>>>  (P 20) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd_events_by_students_extract = (rdd_events_by_students\n",
    "    .map(lambda x: (x[0],extractPatterns(x[1])))\n",
    "    .map(lambda x: (x[0],patternsConcat(x[1])))\n",
    ")\n",
    "\n",
    "rdd_events_by_students_extract.persist()\n",
    "\n",
    "# Looks at the data for a student, now that it's sorted by TimeStamps\n",
    "def displayStudentsPatterns(rdd,students):\n",
    "    for studentID,patterns in rdd.filter(lambda x:x[0] in students.keys()).collect():\n",
    "        print(studentID, students[studentID])\n",
    "        for pb in sorted(patterns.keys()):\n",
    "            print(pb,end='\\t>>>  ')\n",
    "            for event in patterns[pb]:\n",
    "                print(eventToString(event), end=\" \")\n",
    "            print()\n",
    "        print()\n",
    "\n",
    "displayStudentsPatterns(rdd_events_by_students_extract,TEST_STUDENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VVVVVVVVPPPPPPPPVP', <pyspark.resultiterable.ResultIterable object at 0x7f2aec8789e8>)\n"
     ]
    }
   ],
   "source": [
    "def eventToLetter(event):\n",
    "    return {\n",
    "        \"Problem\": lambda x:\"P\",\n",
    "        \"Video\": lambda x:\"V\",\n",
    "        \"Forum\": lambda x:\"F\",\n",
    "    }[event['EventType']](event)\n",
    "\n",
    "def patternToSimpleString(pattern):\n",
    "    return \"\".join([eventToLetter(event) for event in pattern])\n",
    "\n",
    "# Uses the method flatMap on the students patterns table to have a table of all the patterns\n",
    "rdd_patterns = (rdd_events_by_students_extract\n",
    "    .flatMap(lambda x: [\n",
    "        ((patternToSimpleString(x[1][pb]),pb),1) for pb in x[1].keys() \n",
    "    ])\n",
    "    .filter(lambda x: 'P' in x[0][0])\n",
    "    .reduceByKey(lambda a,b: a+b)\n",
    "    .map(lambda x: (x[0][0],{'problem':x[0][1],'count':x[1]}))\n",
    "    .groupByKey()\n",
    ")\n",
    "\n",
    "rdd_patterns.persist()\n",
    "print(rdd_patterns.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5991 \t P\n",
      "\t {'problem': 17, 'count': 1147}\n",
      "\t {'problem': 7, 'count': 1104}\n",
      "\t {'problem': 6, 'count': 1043}\n",
      "\t {'problem': 20, 'count': 988}\n",
      "\t {'problem': 12, 'count': 903}\n",
      "\t {'problem': 14, 'count': 806}\n",
      "5388 \t VVVVVVVP\n",
      "\t {'problem': 7, 'count': 2674}\n",
      "\t {'problem': 6, 'count': 1428}\n",
      "\t {'problem': 17, 'count': 731}\n",
      "\t {'problem': 20, 'count': 376}\n",
      "\t {'problem': 14, 'count': 131}\n",
      "\t {'problem': 12, 'count': 48}\n",
      "2645 \t PP\n",
      "\t {'problem': 6, 'count': 552}\n",
      "\t {'problem': 14, 'count': 448}\n",
      "\t {'problem': 12, 'count': 438}\n",
      "\t {'problem': 20, 'count': 414}\n",
      "\t {'problem': 17, 'count': 412}\n",
      "\t {'problem': 7, 'count': 381}\n",
      "2299 \t VVVVVVVPP\n",
      "\t {'problem': 7, 'count': 858}\n",
      "\t {'problem': 6, 'count': 747}\n",
      "\t {'problem': 20, 'count': 313}\n",
      "\t {'problem': 17, 'count': 263}\n",
      "\t {'problem': 14, 'count': 95}\n",
      "\t {'problem': 12, 'count': 23}\n"
     ]
    }
   ],
   "source": [
    "def sumCount(counts):\n",
    "    return sum([i['count'] for i in counts])\n",
    "\n",
    "# filters and shows the most common patterns \n",
    "for pattern in sorted(rdd_patterns.collect(), key=(lambda x: sumCount(x[1])), reverse=True)[:4]:\n",
    "    print(sumCount(pattern[1]),'\\t',pattern[0])\n",
    "    for example in sorted(pattern[1],key=(lambda x: x['count']), reverse=True):\n",
    "        print(\"\\t\",example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VVVVVVVVPPPPPPPPVP', <pyspark.resultiterable.ResultIterable object at 0x7f2aec87c1d0>)\n"
     ]
    }
   ],
   "source": [
    "def firstAndLastGrades(pattern):\n",
    "    grades = [problem['Grade'] for problem in pattern if problem['EventType']=='Problem']\n",
    "    if grades:\n",
    "        return (grades[0],grades[-1])\n",
    "    else:\n",
    "        return (-1,-1)\n",
    "    \n",
    "# Uses the method flatMap on the students patterns table to have a table of all the patterns\n",
    "rdd_patterns_with_grades = (rdd_events_by_students_extract\n",
    "    .flatMap(lambda x: [\n",
    "        (patternToSimpleString(x[1][pb]),firstAndLastGrades(x[1][pb])) for pb in x[1].keys() \n",
    "    ])\n",
    "    .filter(lambda x: 'P' in x[0])\n",
    "    .groupByKey()\n",
    ")\n",
    "\n",
    "rdd_patterns_with_grades.persist()\n",
    "print(rdd_patterns_with_grades.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "VVVVVVVP\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "PP\n",
      "\t (9.56000041962, 10.0)\n",
      "\t (9.92000007629, 10.0)\n",
      "\t (8.43999958038, 9.97999954224)\n",
      "VVVVVVVPP\n",
      "\t (9.5, 9.92000007629)\n",
      "\t (10.0, 10.0)\n",
      "\t (9.92000007629, 10.0)\n",
      "VVVP\n",
      "\t (7.82000017166, 7.82000017166)\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "VVVVVVP\n",
      "\t (10.0, 10.0)\n",
      "\t (9.55000019073, 9.55000019073)\n",
      "\t (10.0, 10.0)\n",
      "VP\n",
      "\t (7.09000015259, 7.09000015259)\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "VVVVVVVVVP\n",
      "\t (10.0, 10.0)\n",
      "\t (10.0, 10.0)\n",
      "\t (3.25999999046, 3.25999999046)\n",
      "PPP\n",
      "\t (7.05000019073, 8.27999973297)\n",
      "\t (2.0, 10.0)\n",
      "\t (9.26000022888, 10.0)\n",
      "VVVVVVPP\n",
      "\t (9.85000038147, 10.0)\n",
      "\t (8.65999984741, 9.55000019073)\n",
      "\t (6.13000011444, 9.55000019073)\n"
     ]
    }
   ],
   "source": [
    "# filters and shows the most common patterns \n",
    "for pattern in sorted(rdd_patterns_with_grades.collect(), key=(lambda x: len(x[1])), reverse=True)[:10]:\n",
    "    print(pattern[0])\n",
    "    for example in list(pattern[1])[:3]:\n",
    "        print(\"\\t\",example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
